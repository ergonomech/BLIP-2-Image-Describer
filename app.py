import gradio as gr
import torch
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from PIL import Image
import os
import platform

# Function to get the operating system and hostname
def get_hostname_and_os():
    os_type = platform.system()
    hostname = os.getenv('COMPUTERNAME') if os_type == 'Windows' else os.uname().nodename
    return os_type, hostname

# Function to determine the best available device, preferring CUDA if available
def get_best_device():
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():  # Apple M1/M2 (Metal)
        return "mps"
    elif torch.backends.opencl.is_available():  # AMD/Intel GPUs with OpenCL support
        return "opencl"
    else:
        return "cpu"  # Fallback to CPU if no other options are available

# Function to load model based on user-specified model ID and precision
def load_model(model_id="Salesforce/blip2-flan-t5-xl-coco", precision="FP16"):
    device = get_best_device()
    print(f"Loading model '{model_id}' on {device} with {precision} precision...")
    
    # Configure model loading based on user-selected precision
    try:
        if precision == "FP16":
            model = Blip2ForConditionalGeneration.from_pretrained(
                model_id, device_map="auto", torch_dtype=torch.float16
            )
        elif precision == "INT8":
            model = Blip2ForConditionalGeneration.from_pretrained(
                model_id, load_in_8bit=True, device_map="auto"
            )
        elif precision == "BF16":
            model = Blip2ForConditionalGeneration.from_pretrained(
                model_id, device_map="auto", torch_dtype=torch.bfloat16
            )
        else:  # FP32 or default precision
            model = Blip2ForConditionalGeneration.from_pretrained(
                model_id, device_map="auto"
            )
        processor = Blip2Processor.from_pretrained(model_id)
        model.to(device)
        return processor, model, f"Model '{model_id}' loaded successfully on {device} with {precision} precision."
    except Exception as e:
        return None, None, f"Error loading model '{model_id}': {str(e)}"

# Function to generate a description for an image with maximum token usage
def generate_description(image, model_id="Salesforce/blip2-flan-t5-xl-coco", precision="FP16"):
    # Load model dynamically for each request to avoid offloading issues
    processor, model, load_status = load_model(model_id, precision)
    if model is None:
        return load_status  # Return error message if model failed to load

    # Process the image and generate a long-form description
    inputs = processor(images=image, return_tensors="pt").to(model.device)
    generated_ids = model.generate(
        **inputs,
        max_new_tokens=512,           # Adjust for longer outputs
        num_beams=5,                  # Beam search for diversity in descriptions
        repetition_penalty=1.2,       # Penalty to reduce repetitive descriptions
        length_penalty=1.0,           # Adjusts favorably for longer descriptions
        no_repeat_ngram_size=3        # Avoids repeated phrases for clarity
    )
    description = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()

    # Manually delete model to free memory
    del model
    torch.cuda.empty_cache()  # Clear cache for CUDA to prevent memory leaks
    return f"{load_status}\n\nDescription:\n{description}"

# Gradio interface setup
def build_ui():
    with gr.Blocks(theme='gradio/monochrome', analytics_enabled=False, css=".gradio-container { max-width: 100%; }") as app:
        gr.Markdown("# BLIP-2 Image Describer with Model Selection and Precision Control")
        gr.Markdown("Upload an image to receive a detailed description generated by the BLIP-2 model. Enter a Hugging Face model ID, choose a precision, and the app will load and unload the model per request to avoid memory issues.")

        with gr.Row():
            with gr.Column():
                image_input = gr.Image(type="pil", label="Upload Image")
                model_id_input = gr.Textbox(value="Salesforce/blip2-flan-t5-xl-coco", label="Hugging Face Model ID")
                model_precision_input = gr.Dropdown(
                    choices=["FP16", "INT8", "BF16", "FP32"],
                    value="FP16",
                    label="Model Loading Precision"
                )
                submit_button = gr.Button("Generate Description")
            with gr.Column():
                description_output = gr.Textbox(label="Output", lines=20)

        # Trigger description generation on button click
        submit_button.click(
            fn=generate_description,
            inputs=[image_input, model_id_input, model_precision_input],
            outputs=description_output
        )
    
    return app

if __name__ == "__main__":
    os_type, hostname = get_hostname_and_os()
    app = build_ui()
    app.launch(server_port=7862, server_name=hostname, debug=False, show_api=False, width="100%", inbrowser=True)
